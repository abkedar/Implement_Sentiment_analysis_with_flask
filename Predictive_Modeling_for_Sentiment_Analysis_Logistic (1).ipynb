{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "Predictive_Modeling_for_Sentiment_Analysis_Logistic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Oy_cnwscRoD"
      },
      "source": [
        "# Import necessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nHKycl44cRoN",
        "outputId": "249b2eaf-ea30-43cd-81fd-22d8fc16665f"
      },
      "source": [
        "# Import required Libraries\n",
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from contractions import CONTRACTION_MAP\n",
        "import unicodedata\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "nlp = spacy.load('en', parse = False, tag=False, entity=False)\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS9IDAV7k-wP",
        "outputId": "fd3d38e5-1ce1-49ae-e95b-e9f41fb7bf8f"
      },
      "source": [
        "# Load train Data set\r\n",
        "df_tr = pd.read_csv(\"/content/sentiment.csv\", error_bad_lines=False, sep='\\t')\r\n",
        "#df.head()\r\n",
        "\r\n",
        "df_tr.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHh-mv72zsd_",
        "outputId": "89587b39-7fbe-4326-ef08-afff2a9f5f78"
      },
      "source": [
        "# load test data\r\n",
        "df_ts = pd.read_csv(\"/content/sentiment_tst.csv\", error_bad_lines=False, sep='\\t')\r\n",
        "df_ts.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6727nC_3r0cK",
        "outputId": "645ff6bc-fd33-4090-8044-47846aed84f2"
      },
      "source": [
        "df1 = pd.concat([df_tr, df_ts]).reset_index(drop=True)\r\n",
        "df1.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LApnaLLCr42U",
        "outputId": "5a412ae1-b230-4441-83da-11574dbc57d7"
      },
      "source": [
        "df = df1[:35000]\r\n",
        "df_ts = df1[35000:]\r\n",
        "print(df.shape)\r\n",
        "print(df_ts.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 3)\n",
            "(15000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reuLBbg2cRoP"
      },
      "source": [
        "# Cleaning Text - strip HTML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ExoBRd4lcRoP"
      },
      "source": [
        "# function to remove html code in the text rwas data\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")#.get_text()\n",
        "    stripped_text = soup.get_text()\n",
        "    return stripped_text"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqsBqWRlcRoQ"
      },
      "source": [
        "# Removing accented characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "5_s-ujGLcRoQ"
      },
      "source": [
        "# Function bring the text to normal string format\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WhogiJFcRoQ"
      },
      "source": [
        "# Expanding Contractions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "dsp9mUqTcRoR"
      },
      "source": [
        "# Function text data contain word like don't, does'nt, so convert them to do not, does not\n",
        "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
        "    \n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
        "                                      flags=re.IGNORECASE|re.DOTALL)\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contraction_mapping.get(match)\\\n",
        "                                if contraction_mapping.get(match)\\\n",
        "                                else contraction_mapping.get(match.lower())                       \n",
        "        expanded_contraction = first_char+expanded_contraction[1:]\n",
        "        return expanded_contraction\n",
        "        \n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWNNXNjGcRoR"
      },
      "source": [
        "# Removing Special Characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "FRb_hlwwcRoS"
      },
      "source": [
        "# Function remove special character other then alphabet and number\n",
        "def remove_special_characters(text):\n",
        "    text = re.sub('[^a-zA-z0-9\\s]', '', text)\n",
        "    return text"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmdhORKLcRoS"
      },
      "source": [
        "# Lemmatizing text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Kb0p_U7_cRoT"
      },
      "source": [
        "# Function bring the pural, abjective word to root form.\n",
        "def lemmatize_text(text):\n",
        "    text = nlp(text)\n",
        "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    return text"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggTrklg7cRoT"
      },
      "source": [
        "# Removing Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PUSv7375cRoT"
      },
      "source": [
        "# Function to remove stopword using NLTK Libraries\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z67xaNFKcRoU"
      },
      "source": [
        "# Normalize text corpus - tying it all together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9eUcYO2qcRoU"
      },
      "source": [
        "# Combining all above function in above function in one and carry the Text cleaning data\n",
        "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
        "                     accented_char_removal=True, text_lower_case=True, \n",
        "                     text_lemmatization=True, special_char_removal=True, \n",
        "                     stopword_removal=True):\n",
        "    \n",
        "    normalized_corpus = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # strip HTML\n",
        "        if html_stripping:\n",
        "            doc = strip_html_tags(doc)\n",
        "        # remove accented characters\n",
        "        if accented_char_removal:\n",
        "            doc = remove_accented_chars(doc)\n",
        "        # expand contractions    \n",
        "        if contraction_expansion:\n",
        "            doc = expand_contractions(doc)\n",
        "        # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove extra newlines\n",
        "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
        "        # insert spaces between special characters to isolate them    \n",
        "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "        # lemmatize text\n",
        "        if text_lemmatization:\n",
        "            doc = lemmatize_text(doc)\n",
        "        # remove special characters    \n",
        "        if special_char_removal:\n",
        "            doc = remove_special_characters(doc)  \n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "        # remove stopwords\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
        "            \n",
        "        normalized_corpus.append(doc)\n",
        "        \n",
        "    return normalized_corpus\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WRc5tzucRoV"
      },
      "source": [
        "# Model predictions of movie review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUpdAzJl4YUV"
      },
      "source": [
        "# Import Scikit Learn Libraries for model prediction.\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.base import clone\r\n",
        "from sklearn.metrics import roc_curve, auc \r\n",
        "\r\n",
        "from sklearn import metrics"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldOjGeJEcRoX",
        "outputId": "55145e47-fc62-4894-9158-ee80dd05fc91"
      },
      "source": [
        "# Run the Cleaning process function of text data in train data set\r\n",
        "df['cleaned_re'] = normalize_corpus(df['review'])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5es_0Fvs9Mt",
        "outputId": "03b7fa12-8a25-419d-ebc6-a4ffa10bf612"
      },
      "source": [
        "# Run the Cleaning process function of text data in test data set\r\n",
        "df_ts['cleaned_re'] = normalize_corpus(df_ts['review'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "WgA3q_Lk55eU",
        "outputId": "83534973-d484-4557-b0cd-4b1c5e3d92b1"
      },
      "source": [
        "df_ts.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>cleaned_re</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35000</th>\n",
              "      <td>10000</td>\n",
              "      <td>Worthless movie. A complete waste of time and ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>worthless movie complete waste time nothing ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35001</th>\n",
              "      <td>10001</td>\n",
              "      <td>This crock of doodoo won a award? They must ha...</td>\n",
              "      <td>negative</td>\n",
              "      <td>crock doodoo win award must desperate give awa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35002</th>\n",
              "      <td>10002</td>\n",
              "      <td>A traveling couple (Horton and Hamilton)stumbl...</td>\n",
              "      <td>negative</td>\n",
              "      <td>travel couple horton hamilton stumble onto tow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35003</th>\n",
              "      <td>10003</td>\n",
              "      <td>The scientist Charles and his wife (or assista...</td>\n",
              "      <td>negative</td>\n",
              "      <td>scientist charles wife assistant marissa recei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35004</th>\n",
              "      <td>10004</td>\n",
              "      <td>Comparisons to the original series are inevita...</td>\n",
              "      <td>negative</td>\n",
              "      <td>comparison original series inevitable shame di...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                         cleaned_re\n",
              "35000       10000  ...  worthless movie complete waste time nothing ex...\n",
              "35001       10001  ...  crock doodoo win award must desperate give awa...\n",
              "35002       10002  ...  travel couple horton hamilton stumble onto tow...\n",
              "35003       10003  ...  scientist charles wife assistant marissa recei...\n",
              "35004       10004  ...  comparison original series inevitable shame di...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C73caT8h5l1-"
      },
      "source": [
        "# take a peek at the data\r\n",
        "reviews = np.array(df['cleaned_re'])\r\n",
        "sentiments = np.array(df['sentiment'])\r\n",
        "\r\n",
        "reviews_ts = np.array(df_ts['cleaned_re'])\r\n",
        "sentiments_ts = np.array(df_ts['sentiment'])\r\n",
        "\r\n",
        "# build train and test datasets\r\n",
        "norm_train_reviews = reviews\r\n",
        "train_sentiments = sentiments\r\n",
        "norm_test_reviews = reviews_ts\r\n",
        "test_sentiments = sentiments_ts"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5yhUlg09Etm"
      },
      "source": [
        "# build BOW features on train reviews\r\n",
        "cv = CountVectorizer(binary=False, min_df=0.0, max_df=2.0, ngram_range=(1,3))\r\n",
        "cv_train_features = cv.fit_transform(norm_train_reviews)\r\n",
        "\r\n",
        "# build TFIDF features on train reviews\r\n",
        "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=100, ngram_range=(1,3),\r\n",
        "                     sublinear_tf=True)\r\n",
        "tv_train_features = tv.fit_transform(norm_train_reviews)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9anuBLH4i05"
      },
      "source": [
        "# transform test reviews into features\r\n",
        "cv_test_features = cv.transform(norm_test_reviews)\r\n",
        "tv_test_features = tv.transform(norm_test_reviews)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3eoLt814KDX"
      },
      "source": [
        "def train_predict_model(classifier, \r\n",
        "                        train_features, train_labels, \r\n",
        "                        test_features, test_labels):\r\n",
        "    # build model    \r\n",
        "    classifier.fit(train_features, train_labels)\r\n",
        "    # predict using model\r\n",
        "    predictions = classifier.predict(test_features) \r\n",
        "    return predictions "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZMmcNtoAes4"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling \r\n",
        "def display_classification_report(true_labels, predicted_labels, classes=[1,0]):\r\n",
        "\r\n",
        "    report = metrics.classification_report(y_true=true_labels, \r\n",
        "                                           y_pred=predicted_labels, \r\n",
        "                                           labels=classes) \r\n",
        "    print(report)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF-OK5-TAlbf"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling\r\n",
        "def display_confusion_matrix(true_labels, predicted_labels, classes=[1,0]):\r\n",
        "    \r\n",
        "    total_classes = len(classes)\r\n",
        "    level_labels = [total_classes*[0], list(range(total_classes))]\r\n",
        "\r\n",
        "    cm = metrics.confusion_matrix(y_true=true_labels, y_pred=predicted_labels, \r\n",
        "                                  labels=classes)\r\n",
        "    cm_frame = pd.DataFrame(data=cm, \r\n",
        "                            columns=pd.MultiIndex(levels=[['Predicted:'], classes], \r\n",
        "                                                  codes=level_labels), \r\n",
        "                            index=pd.MultiIndex(levels=[['Actual:'], classes], \r\n",
        "                                                codes=level_labels)) \r\n",
        "    print(cm_frame) "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vj8CWz3-dMJ"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling \r\n",
        "def display_model_performance_metrics(true_labels, predicted_labels, classes=[1,0]):\r\n",
        "    print('Model Performance metrics:')\r\n",
        "    print('-'*30)\r\n",
        "    get_metrics(true_labels=true_labels, predicted_labels=predicted_labels)\r\n",
        "    print('\\nModel Classification report:')\r\n",
        "    print('-'*30)\r\n",
        "    display_classification_report(true_labels=true_labels, predicted_labels=predicted_labels, \r\n",
        "                                  classes=classes)\r\n",
        "    print('\\nPrediction Confusion Matrix:')\r\n",
        "    print('-'*30)\r\n",
        "    display_confusion_matrix(true_labels=true_labels, predicted_labels=predicted_labels, \r\n",
        "                             classes=classes)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8G3ftCq-uno"
      },
      "source": [
        "# Run the metrics function to display the performance of predictive modeling \r\n",
        "def get_metrics(true_labels, predicted_labels):\r\n",
        "    \r\n",
        "    print('Accuracy:', np.round(\r\n",
        "                        metrics.accuracy_score(true_labels, \r\n",
        "                                               predicted_labels),\r\n",
        "                        4))\r\n",
        "    print('Precision:', np.round(\r\n",
        "                        metrics.precision_score(true_labels, \r\n",
        "                                               predicted_labels,\r\n",
        "                                               average='weighted'),\r\n",
        "                        4))\r\n",
        "    print('Recall:', np.round(\r\n",
        "                        metrics.recall_score(true_labels, \r\n",
        "                                               predicted_labels,\r\n",
        "                                               average='weighted'),\r\n",
        "                        4))\r\n",
        "    print('F1 Score:', np.round(\r\n",
        "                        metrics.f1_score(true_labels, \r\n",
        "                                               predicted_labels,\r\n",
        "                                               average='weighted'),\r\n",
        "                        4))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwL5hnaW9bV1",
        "outputId": "e8391dbf-3908-454b-e1e6-9a2ec7e1d49e"
      },
      "source": [
        "print('BOW model:> Train features shape:', cv_train_features.shape, ' Test features shape:', cv_test_features.shape)\r\n",
        "print('TFIDF model:> Train features shape:', tv_train_features.shape, ' Test features shape:', tv_test_features.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BOW model:> Train features shape: (35000, 5937418)  Test features shape: (15000, 5937418)\n",
            "TFIDF model:> Train features shape: (35000, 5931526)  Test features shape: (15000, 5931526)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJySmWUA9qQq"
      },
      "source": [
        "### Model Training, Prediction and Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w26OcM3p9eIc"
      },
      "source": [
        "# Predictive modeling\r\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\r\n",
        "\r\n",
        "lr = LogisticRegression(penalty='l2', max_iter=300, C=1)\r\n",
        "svm = SGDClassifier(loss='hinge', max_iter=600)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waOV1F3Z9wVk",
        "outputId": "8598a9d7-16d4-441a-f3cc-6c49eeb10f9e"
      },
      "source": [
        "lr_bow_predictions = train_predict_model(classifier=lr, \r\n",
        "                                             train_features=cv_train_features, train_labels=train_sentiments,\r\n",
        "                                             test_features=cv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, predicted_labels=lr_bow_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.9003\n",
            "Precision: 0.9005\n",
            "Recall: 0.9003\n",
            "F1 Score: 0.9003\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.89      0.91      0.90      7467\n",
            "    negative       0.91      0.89      0.90      7533\n",
            "\n",
            "    accuracy                           0.90     15000\n",
            "   macro avg       0.90      0.90      0.90     15000\n",
            "weighted avg       0.90      0.90      0.90     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6802      665\n",
            "        negative        830     6703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sPaWDG76Qdb"
      },
      "source": [
        "#!pip install pickle-mixin"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLEcwKQhCddM",
        "outputId": "d1948b3e-34ba-4ee4-80da-fa26c2662b71"
      },
      "source": [
        "svm_tfidf_predictions = train_predict_model(classifier=svm, \r\n",
        "                                                train_features=tv_train_features, train_labels=train_sentiments,\r\n",
        "                                                test_features=tv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=svm_tfidf_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.7665\n",
            "Precision: 0.827\n",
            "Recall: 0.7665\n",
            "F1 Score: 0.7555\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.69      0.98      0.81      7467\n",
            "    negative       0.97      0.55      0.70      7533\n",
            "\n",
            "    accuracy                           0.77     15000\n",
            "   macro avg       0.83      0.77      0.76     15000\n",
            "weighted avg       0.83      0.77      0.76     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       7326      141\n",
            "        negative       3361     4172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQIhEV0VCpAk"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YbynnR6OTOu"
      },
      "source": [
        "randomclassifier=RandomForestClassifier(n_estimators=200,criterion='entropy')   # 100"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_ye7Sg0OpHl",
        "outputId": "638059b9-0fae-44d8-b984-911ad6e6ff2a"
      },
      "source": [
        "# Random Forest model on TF-IDF features\r\n",
        "svm_tfidf_predictions = train_predict_model(classifier=randomclassifier, \r\n",
        "                                                train_features=tv_train_features, train_labels=train_sentiments,\r\n",
        "                                                test_features=tv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=svm_tfidf_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.8381\n",
            "Precision: 0.8394\n",
            "Recall: 0.8381\n",
            "F1 Score: 0.8379\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.82      0.87      0.84      7467\n",
            "    negative       0.86      0.81      0.83      7533\n",
            "\n",
            "    accuracy                           0.84     15000\n",
            "   macro avg       0.84      0.84      0.84     15000\n",
            "weighted avg       0.84      0.84      0.84     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6486      981\n",
            "        negative       1448     6085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SnzoFlzPESz",
        "outputId": "70daf497-1760-466a-fdf2-722cf176b9b7"
      },
      "source": [
        "# Randome Forest model on BOW features\r\n",
        "# Please Note : the module meu is not been provided.\r\n",
        "random_bow_predictions = train_predict_model(classifier=randomclassifier, \r\n",
        "                                             train_features=cv_train_features, train_labels=train_sentiments,\r\n",
        "                                             test_features=cv_test_features, test_labels=test_sentiments)\r\n",
        "display_model_performance_metrics(true_labels=test_sentiments, \r\n",
        "                                      predicted_labels=random_bow_predictions,\r\n",
        "                                      classes=['positive', 'negative'])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Performance metrics:\n",
            "------------------------------\n",
            "Accuracy: 0.8703\n",
            "Precision: 0.8709\n",
            "Recall: 0.8703\n",
            "F1 Score: 0.8702\n",
            "\n",
            "Model Classification report:\n",
            "------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    positive       0.86      0.89      0.87      7467\n",
            "    negative       0.89      0.85      0.87      7533\n",
            "\n",
            "    accuracy                           0.87     15000\n",
            "   macro avg       0.87      0.87      0.87     15000\n",
            "weighted avg       0.87      0.87      0.87     15000\n",
            "\n",
            "\n",
            "Prediction Confusion Matrix:\n",
            "------------------------------\n",
            "                 Predicted:         \n",
            "                   positive negative\n",
            "Actual: positive       6641      826\n",
            "        negative       1120     6413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FALjdhKEQZss"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\r\n",
        "\r\n",
        "scores = cross_val_score(lr, cv_train_features, train_sentiments, cv=5)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAlwR3XABfBc",
        "outputId": "b28693a6-feb1-480b-fe3e-30c521ffe7f1"
      },
      "source": [
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.90 accuracy with a standard deviation of 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq4tw9txY-d4"
      },
      "source": [
        "scores1 = cross_val_score(lr, tv_train_features, train_sentiments, cv=8)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xvdITKVjjKd",
        "outputId": "c811d822-a20c-42af-b30f-bd2b9f612e85"
      },
      "source": [
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores1.mean(), scores1.std()))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.87 accuracy with a standard deviation of 0.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zELP26wgqlZ8"
      },
      "source": [
        "# Conclusion:\r\n",
        "- The result of cross validation score.mean() as 90% with score.std() 0.0 for Count-Vectorizer, which mean this is extremely low, which means that our model has a very low variance, which is actually very good since that means that the prediction that we obtained on one test set is not by chance. Rather, the model will perform more or less similar on all test sets.\r\n",
        "- The result of cross validation score.mean() as 87% with score.std() 0.01 for Tf-idfVectorizer, which mean this is extremely low, which means that our model has a very low variance, which is actually very good since that means that the prediction that we obtained on one test set is not by chance. Rather, the model will perform more or less similar on all test sets.\r\n",
        "- But comparing both performance then the train data from to bag of word using Count-Vectorizer is bettern then Tf-idfVectorizer.\r\n",
        "So deplyoment purpose we will result obtain by Count-Vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05AnkLURkO5N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}